<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Iris Voice Assistant</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background-color: black;
      color: white;
      font-family: sans-serif;
      height: 100%;
      overflow: hidden;
    }
    #avatar {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100%;
      position: relative;
    }
    video {
      max-height: 100vh;
    }
    #status {
      position: absolute;
      bottom: 20px;
      left: 0;
      right: 0;
      text-align: center;
      padding: 8px;
      color: rgba(255,255,255,0.7);
      font-size: 14px;
      transition: opacity 0.3s;
    }
    .listening #status {
      color: rgba(100,255,100,0.9);
    }
    .processing #status {
      color: rgba(255,200,0,0.9);
    }
    .speaking #status {
      color: rgba(100,200,255,0.9);
    }
    .error #status {
      color: rgba(255,100,100,0.9);
    }
    #startButton {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      padding: 20px 40px;
      font-size: 24px;
      background-color: #4CAF50;
      color: white;
      border: none;
      border-radius: 50px;
      cursor: pointer;
      z-index: 1000;
      box-shadow: 0 8px 16px rgba(0,0,0,0.3);
    }
    #transcript {
      position: absolute;
      bottom: 50px;
      left: 0;
      right: 0;
      text-align: center;
      padding: 10px;
      color: white;
      background-color: rgba(0,0,0,0.5);
      font-size: 16px;
    }
    #debugPanel {
      position: absolute;
      bottom: 10px;
      right: 10px;
      background-color: rgba(0,0,0,0.7);
      padding: 10px;
      border-radius: 5px;
      font-size: 12px;
      max-width: 300px;
      display: none;
    }
    #manualInput {
      position: absolute;
      bottom: 100px;
      left: 0;
      right: 0;
      margin: 0 auto;
      width: 80%;
      max-width: 500px;
      padding: 10px;
      background-color: rgba(0,0,0,0.7);
      border: 1px solid #444;
      border-radius: 5px;
      font-size: 16px;
      color: white;
      display: none;
    }
  </style>
</head>
<body>
  <div id="avatar">
    <video autoplay muted loop id="avatarVideo">
      <source src="nova-avatar-loop.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
    <div id="status">Press Start to activate Iris</div>
    <div id="transcript"></div>
    <button id="startButton">Start Iris</button>
    <input type="text" id="manualInput" placeholder="Type your message and press Enter..." />
    <div id="debugPanel"></div>
  </div>
  
  <script>
    // Session ID for Dialogflow
    const sessionId = Date.now().toString();
    
    // Server URL
    const SERVER_URL = "https://irisnova-prototype.onrender.com";
    
    // DOM Elements
    const statusEl = document.getElementById('status');
    const avatarEl = document.getElementById('avatar');
    const startButton = document.getElementById('startButton');
    const transcriptEl = document.getElementById('transcript');
    const debugPanel = document.getElementById('debugPanel');
    const manualInput = document.getElementById('manualInput');
    
    // Speech services
    let recognition = null;
    let isListening = false;
    let initialized = false;
    
    // Show debug information
    function debug(message) {
      console.log(message);
      debugPanel.style.display = 'block';
      debugPanel.innerHTML += message + '<br>';
      
      // Keep only the last 10 lines
      const lines = debugPanel.innerHTML.split('<br>');
      if (lines.length > 10) {
        debugPanel.innerHTML = lines.slice(lines.length - 10).join('<br>');
      }
    }
    
    // Set status with visual feedback
    function setStatus(message, state = '') {
      debug(`Status: ${message} (${state})`);
      statusEl.textContent = message;
      avatarEl.className = state;
    }
    
    // Simple speech function
    function speak(text) {
      try {
        debug(`Speaking: "${text}"`);
        
        // Cancel any ongoing speech
        window.speechSynthesis.cancel();
        
        // Create utterance
        const utterance = new SpeechSynthesisUtterance(text);
        
        // Get voices
        const voices = window.speechSynthesis.getVoices();
        debug(`Available voices: ${voices.length}`);
        
        // Try to find a female voice
        const femaleVoice = voices.find(v => 
          (v.name.toLowerCase().includes('female') || 
           v.name.toLowerCase().includes('samantha')) && 
          v.lang.includes('en')
        );
        
        if (femaleVoice) {
          debug(`Using voice: ${femaleVoice.name}`);
          utterance.voice = femaleVoice;
        } else {
          debug("No female voice found, using default");
        }
        
        // Set status
        setStatus('Iris is speaking...', 'speaking');
        
        // Speak
        window.speechSynthesis.speak(utterance);
        
        // Set up an event for when speech ends
        utterance.onend = function() {
          debug("Speech ended");
          setStatus('Listening...', 'listening');
          
          // Restart listening if we should be listening
          if (isListening && (!recognition || !recognition.recognizing)) {
            startListening();
          }
        };
        
        return true;
      } catch (error) {
        debug(`Speak error: ${error.message}`);
        setStatus('Listening...', 'listening');
        return false;
      }
    }
    
    // Process user input with Dialogflow
    async function processInput(userInput) {
      try {
        // Update UI
        transcriptEl.textContent = `You: ${userInput}`;
        setStatus('Processing...', 'processing');
        
        // Send to server with session ID
        const response = await fetch(`${SERVER_URL}/query`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ 
            query: userInput,
            sessionId: sessionId  // Send session ID to maintain conversation
          })
        });
        
        // Check for errors
        if (!response.ok) {
          throw new Error(`Server returned ${response.status}: ${response.statusText}`);
        }
        
        // Parse response
        const data = await response.json();
        debug(`Response: ${JSON.stringify(data)}`);
        
        // Check for valid response
        if (data && data.reply) {
          // Update transcript
          transcriptEl.textContent += `\nIris: ${data.reply}`;
          
          // Try to speak
          speak(data.reply);
        } else {
          throw new Error('Empty or invalid response from server');
        }
      } catch (error) {
        debug(`Process error: ${error.message}`);
        setStatus('Error processing request', 'error');
        speak("I'm sorry, I encountered an error. Please try again.");
      }
    }
    
    // Start speech recognition
    function startListening() {
      try {
        // Create recognition object if needed
        if (!recognition) {
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          if (!SpeechRecognition) {
            throw new Error("Speech recognition not supported in this browser");
          }
          
          recognition = new SpeechRecognition();
          recognition.continuous = false;
          recognition.interimResults = false;
          recognition.lang = 'en-US';
          
          recognition.onstart = function() {
            recognition.recognizing = true;
            setStatus('Listening...', 'listening');
          };
          
          recognition.onresult = function(event) {
            recognition.recognizing = false;
            const userInput = event.results[0][0].transcript;
            debug(`Recognized: "${userInput}" (confidence: ${event.results[0][0].confidence.toFixed(2)})`);
            processInput(userInput);
          };
          
          recognition.onerror = function(event) {
            recognition.recognizing = false;
            debug(`Recognition error: ${event.error}`);
            
            if (event.error === 'no-speech') {
              setStatus('Waiting for speech...', 'listening');
              setTimeout(startListening, 1000);
            } else if (event.error === 'aborted') {
              // Do nothing
            } else {
              setStatus(`Recognition error: ${event.error}`, 'error');
              setTimeout(startListening, 3000);
            }
          };
          
          recognition.onend = function() {
            recognition.recognizing = false;
            debug("Recognition ended");
            
            // Only restart if we're still supposed to be listening
            if (isListening) {
              debug("Restarting recognition...");
              setTimeout(startListening, 500);
            }
          };
        }
        
        // Stop any existing recognition
        try {
          if (recognition.recognizing) {
            recognition.abort();
          }
        } catch (e) {
          debug(`Error stopping recognition: ${e.message}`);
        }
        
        // Start recognition
        recognition.start();
        recognition.recognizing = true;
        
      } catch (error) {
        debug(`Start listening error: ${error.message}`);
        setStatus('Failed to start speech recognition', 'error');
      }
    }
    
    // Initialize the app
    function initApp() {
      try {
        if (initialized) return;
        
        // Hide start button and show manual input
        startButton.style.display = 'none';
        manualInput.style.display = 'block';
        
        // Set initial status
        setStatus('Initializing...', '');
        
        // Show debug panel
        debugPanel.style.display = 'block';
        debug("App initialized");
        
        // Welcome message with delay to ensure voices are loaded
        setTimeout(() => {
          // Speak welcome message
          speak("Hi there, I'm Iris. How can I help you today?");
          
          // Start listening
          isListening = true;
          initialized = true;
          startListening();
          
          // Focus manual input
          manualInput.focus();
        }, 1000);
        
      } catch (error) {
        debug(`Initialization error: ${error.message}`);
        setStatus('Failed to initialize', 'error');
      }
    }
    
    // Manual input for testing
    manualInput.addEventListener('keydown', function(e) {
      if (e.key === 'Enter') {
        const userInput = manualInput.value.trim();
        if (userInput) {
          debug(`Manual input: "${userInput}"`);
          processInput(userInput);
          manualInput.value = '';
        }
      }
    });
    
    // Start button click handler
    startButton.addEventListener('click', initApp);
    
    // Debug keyboard shortcuts
    document.addEventListener('keydown', function(e) {
      // Press 'D' to toggle debug panel
      if (e.key === 'd' || e.key === 'D') {
        debugPanel.style.display = debugPanel.style.display === 'none' ? 'block' : 'none';
      }
      
      // Press 'T' to test speech
      if (e.key === 't' || e.key === 'T') {
        debug("Testing speech...");
        speak("This is a test of Iris's voice system. Can you hear me clearly?");
      }
      
      // Press 'M' to show/hide manual input
      if (e.key === 'm' || e.key === 'M') {
        manualInput.style.display = manualInput.style.display === 'none' ? 'block' : 'none';
        if (manualInput.style.display === 'block') {
          manualInput.focus();
        }
      }
      
      // Press 'R' to restart listening
      if ((e.key === 'r' || e.key === 'R') && initialized) {
        startListening();
      }
    });
    
    // Global access for console debugging
    window.debugIris = {
      speak: speak,
      startListening: startListening,
      processInput: processInput,
      init: initApp
    };
    
    // Make sure voices are loaded before we allow initialization
    if (window.speechSynthesis) {
      if (window.speechSynthesis.getVoices().length === 0) {
        window.speechSynthesis.onvoiceschanged = function() {
          // Enable the start button once voices are loaded
          startButton.disabled = false;
          debug("Voices loaded");
        };
      } else {
        startButton.disabled = false;
      }
    }
  </script>
</body>
</html>
