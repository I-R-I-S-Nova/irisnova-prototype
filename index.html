<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Iris Voice Assistant</title>
  <style>
    html, body {
      margin: 0;
      padding: 0;
      background-color: black;
      color: white;
      font-family: sans-serif;
      height: 100%;
      overflow: hidden;
    }
    #avatar {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100%;
      position: relative;
    }
    video {
      max-height: 100vh;
    }
    #status {
      position: absolute;
      bottom: 20px;
      left: 0;
      right: 0;
      text-align: center;
      padding: 8px;
      color: rgba(255,255,255,0.7);
      font-size: 14px;
      transition: opacity 0.3s;
    }
    .listening #status {
      color: rgba(100,255,100,0.9);
    }
    .processing #status {
      color: rgba(255,200,0,0.9);
    }
    .speaking #status {
      color: rgba(100,200,255,0.9);
    }
    .error #status {
      color: rgba(255,100,100,0.9);
    }
    #startButton {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      padding: 20px 40px;
      font-size: 24px;
      background-color: #4CAF50;
      color: white;
      border: none;
      border-radius: 50px;
      cursor: pointer;
      z-index: 1000;
      box-shadow: 0 8px 16px rgba(0,0,0,0.3);
    }
    #transcript {
      position: absolute;
      bottom: 50px;
      left: 0;
      right: 0;
      text-align: center;
      padding: 10px;
      color: white;
      background-color: rgba(0,0,0,0.5);
      font-size: 16px;
    }
    #debugPanel {
      position: absolute;
      bottom: 10px;
      right: 10px;
      background-color: rgba(0,0,0,0.7);
      padding: 10px;
      border-radius: 5px;
      font-size: 12px;
      max-width: 300px;
      display: none;
    }
  </style>
</head>
<body>
  <div id="avatar">
    <video autoplay muted loop id="avatarVideo">
      <source src="nova-avatar-loop.mp4" type="video/mp4" />
      Your browser does not support the video tag.
    </video>
    <div id="status">Loading Iris...</div>
    <div id="transcript"></div>
    <div id="debugPanel"></div>
  </div>
  
  <script>
    // Server URL
    const SERVER_URL = "https://irisnova-prototype.onrender.com";
    
    // DOM Elements
    const statusEl = document.getElementById('status');
    const avatarEl = document.getElementById('avatar');
    const transcriptEl = document.getElementById('transcript');
    const debugPanel = document.getElementById('debugPanel');
    
    // Speech services
    let recognition = null;
    let isListening = false;
    let initialized = false;
    let speechInitialized = false;
    
    // Show debug information
    function debug(message) {
      console.log(message);
      //debugPanel.style.display = 'block';
      debugPanel.innerHTML += message + '<br>';
      
      // Keep only the last 10 lines
      const lines = debugPanel.innerHTML.split('<br>');
      if (lines.length > 10) {
        debugPanel.innerHTML = lines.slice(lines.length - 10).join('<br>');
      }
    }
    
    // Set status with visual feedback
    function setStatus(message, state = '') {
      debug(`Status: ${message} (${state})`);
      statusEl.textContent = message;
      avatarEl.className = state;
    }
    
    // Simple speech function with user activation bypass
    function speak(text, isInitialGreeting = false) {
      return new Promise((resolve) => {
        try {
          debug(`Speaking: "${text}"`);
          
          // Cancel any ongoing speech
          if (window.speechSynthesis.speaking) {
            window.speechSynthesis.cancel();
          }
          
          // Create utterance
          const utterance = new SpeechSynthesisUtterance(text);
          
          // Set up event handlers
          utterance.onstart = () => {
            debug("Speech started");
            setStatus('Iris is speaking...', 'speaking');
            speechInitialized = true;
          };
          
          utterance.onend = () => {
            debug("Speech ended");
            setStatus('Listening...', 'listening');
            resolve();
            
            // Start listening after greeting
            if (isInitialGreeting && !isListening) {
              isListening = true;
              startListening();
            }
          };
          
          utterance.onerror = (err) => {
            debug(`Speech error: ${err.error}`);
            resolve();
            
            // Still start listening after greeting, even if speech fails
            if (isInitialGreeting && !isListening) {
              isListening = true;
              startListening();
            }
          };
          
          // Get voices
          const voices = window.speechSynthesis.getVoices();
          
          // Try to find a female voice
          const femaleVoice = voices.find(v => 
            (v.name.toLowerCase().includes('female') || 
             v.name.toLowerCase().includes('samantha')) && 
            v.lang.includes('en')
          );
          
          if (femaleVoice) {
            utterance.voice = femaleVoice;
          }
          
          // Start speaking
          setStatus('Iris is speaking...', 'speaking');
          window.speechSynthesis.speak(utterance);
          
          // Safety timeout for cases where onend doesn't fire
          const safetyTimeout = text.length * 90 + 2000;
          setTimeout(() => {
            if (window.speechSynthesis.speaking) {
              debug(`Safety timeout reached after ${safetyTimeout}ms`);
              resolve();
              
              // Start listening after greeting anyway
              if (isInitialGreeting && !isListening) {
                isListening = true;
                startListening();
              }
            }
          }, safetyTimeout);
          
        } catch (error) {
          debug(`Speak error: ${error.message}`);
          resolve();
          
          // Still start listening after greeting, even if speech fails
          if (isInitialGreeting && !isListening) {
            isListening = true;
            startListening();
          }
        }
      });
    }
    
    // Process user input with Dialogflow
    async function processInput(userInput) {
      try {
        // Update UI
        transcriptEl.textContent = `You: ${userInput}`;
        setStatus('Processing...', 'processing');
        
        // Log the input
        debug(`Processing input: "${userInput}"`);
        
        // Send to server
        const response = await fetch(`${SERVER_URL}/query`, {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ query: userInput })
        });
        
        // Check for errors
        if (!response.ok) {
          throw new Error(`Server returned ${response.status}: ${response.statusText}`);
        }
        
        // Parse response
        const data = await response.json();
        debug(`Response: ${JSON.stringify(data)}`);
        
        // Check for valid response
        if (data && data.reply) {
          // Update transcript
          transcriptEl.textContent += `\nIris: ${data.reply}`;
          
          // Speak the response
          await speak(data.reply);
          
          // Restart listening if needed
          if (isListening && !recognition.recognizing) {
            startListening();
          }
        } else {
          throw new Error('Empty or invalid response from server');
        }
      } catch (error) {
        debug(`Process error: ${error.message}`);
        setStatus('Error processing request', 'error');
        await speak("I'm sorry, I encountered an error. Please try again.");
        
        // Restart listening if needed
        if (isListening && !recognition.recognizing) {
          startListening();
        }
      }
    }
    
    // Start speech recognition
    function startListening() {
      try {
        // Create recognition object if needed
        if (!recognition) {
          const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
          if (!SpeechRecognition) {
            throw new Error("Speech recognition not supported in this browser");
          }
          
          recognition = new SpeechRecognition();
          recognition.continuous = false;
          recognition.interimResults = false;
          recognition.lang = 'en-US';
          
          recognition.onstart = function() {
            debug("Recognition started");
            recognition.recognizing = true;
            setStatus('Listening...', 'listening');
          };
          
          recognition.onresult = function(event) {
            recognition.recognizing = false;
            const userInput = event.results[0][0].transcript;
            debug(`Recognized: "${userInput}" (confidence: ${event.results[0][0].confidence.toFixed(2)})`);
            processInput(userInput);
          };
          
          recognition.onerror = function(event) {
            recognition.recognizing = false;
            debug(`Recognition error: ${event.error}`);
            
            if (event.error === 'no-speech') {
              debug("No speech detected, restarting...");
              setStatus('Waiting for speech...', 'listening');
              setTimeout(startListening, 1000);
            } else if (event.error === 'aborted') {
              debug("Recognition aborted");
            } else {
              setStatus(`Recognition error: ${event.error}`, 'error');
              setTimeout(startListening, 3000);
            }
          };
          
          recognition.onend = function() {
            recognition.recognizing = false;
            debug("Recognition ended");
            
            // Only restart if we're still supposed to be listening
            if (isListening) {
              debug("Restarting recognition...");
              setTimeout(startListening, 500);
            }
          };
        }
        
        // Stop any existing recognition
        try {
          if (recognition.recognizing) {
            recognition.abort();
          }
        } catch (e) {
          debug(`Error stopping recognition: ${e.message}`);
        }
        
        // Start recognition
        recognition.start();
        recognition.recognizing = true;
        
      } catch (error) {
        debug(`Start listening error: ${error.message}`);
        setStatus('Failed to start speech recognition', 'error');
      }
    }
    
    // Special function to initialize speech without user interaction
    function forceInitialGreeting() {
      const greetingText = "Hi there, I'm Iris. How can I help you today?";
      
      // Update transcript with greeting
      transcriptEl.textContent = `Iris: ${greetingText}`;
      
      // Try multiple methods to get speech working
      
      // Method 1: Basic speech synthesis
      speak(greetingText, true)
        .then(() => {
          debug("Initial greeting complete");
        })
        .catch(err => {
          debug(`Initial greeting error: ${err}`);
        });
    }
    
    // Speech synthesis initialization
    function initSpeech() {
      // Load voices
      let voices = [];
      
      function loadVoices() {
        voices = window.speechSynthesis.getVoices();
        debug(`Loaded ${voices.length} voices`);
        
        if (voices.length > 0) {
          // Voices loaded, we can start the greeting
          initialized = true;
          forceInitialGreeting();
        }
      }
      
      // First attempt - voice list might already be available
      if (window.speechSynthesis.getVoices().length > 0) {
        loadVoices();
      } else {
        // Wait for voices to load
        window.speechSynthesis.onvoiceschanged = loadVoices;
        
        // Fallback in case onvoiceschanged doesn't fire
        setTimeout(() => {
          if (!initialized) {
            debug("Voice timeout - attempting greeting anyway");
            initialized = true;
            forceInitialGreeting();
          }
        }, 1000);
      }
    }
    
    // Start initialization on page load
    window.addEventListener('DOMContentLoaded', function() {
      debug("Page loaded, initializing...");
      initSpeech();
    });
    
    // Debug keyboard shortcuts
    document.addEventListener('keydown', function(e) {
      // Press 'D' to toggle debug panel
      if (e.key === 'd' || e.key === 'D') {
        debugPanel.style.display = debugPanel.style.display === 'none' ? 'block' : 'none';
      }
      
      // Press 'T' to test speech
      if (e.key === 't' || e.key === 'T') {
        speak("This is a test of Iris's voice system. Can you hear me clearly?");
      }
      
      // Press 'R' to restart listening
      if (e.key === 'r' || e.key === 'R' && initialized) {
        startListening();
      }
      
      // Press 'G' to repeat greeting
      if (e.key === 'g' || e.key === 'G') {
        forceInitialGreeting();
      }
    });
    
    // Global access for console debugging
    window.debugIris = {
      speak: (text) => speak(text),
      startListening: startListening,
      processInput: processInput,
      forceGreeting: forceInitialGreeting
    };
  </script>
</body>
</html>
